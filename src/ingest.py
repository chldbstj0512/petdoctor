import pandas as pd

from pinecone import Pinecone
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_core.documents import Document

from config import (
    OPENAI_API_KEY,
    PINECONE_API_KEY,
    PINECONE_INDEX,
)

# ğŸ”¥ ì¦ìƒ ë¶„ë¥˜ê¸° import
from categorize import categorize_text


# =========================
# 1ï¸âƒ£ ë™ë¬¼ ì¢…ë¥˜ íŒë‹¨ (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
# =========================

ANIMAL_KEYWORDS = {
    "dog": [
        "ê°•ì•„ì§€", "ë°˜ë ¤ê²¬", "ëŒ•ëŒ•ì´",
        "ë³´ë”ì½œë¦¬", "í‘¸ë“¤", "ë§í‹°ì¦ˆ", "ì‹œë°”",
        "ì‚°ì±…", "ëª©ì¤„", "ë°°ë³€í›ˆë ¨",
    ],
    "cat": [
        "ê³ ì–‘ì´", "ê¸¸ëƒ¥ì´", "ëƒ¥ì´", "ë°˜ë ¤ë¬˜", "ì•¼ì˜¹ì´",
        "ìº£", "ìŠ¤í¬ë˜ì³", "ëª¨ë˜", "í™”ì¥ì‹¤",
        "ìº£íƒ€ì›Œ",
    ],
}


def detect_animal(
    question: str = "",
    title: str = "",
    min_hits: int = 1,
    ratio_threshold: float = 0.4,
) -> str:
    """
    ë™ë¬¼ ì¢…ë¥˜ íŒë³„ (ë¹ˆë„ ê¸°ë°˜)
    - dog / cat í‚¤ì›Œë“œ ì¹´ìš´íŠ¸ ë¹„êµ
    - ì§€ë°°ì ì¸ ìª½ë§Œ í™•ì •
    """

    text = f"{title} {question}"

    scores = {}
    for animal, keywords in ANIMAL_KEYWORDS.items():
        scores[animal] = sum(text.count(kw) for kw in keywords)

    best_animal = max(scores, key=scores.get)
    best_score = scores[best_animal]
    total_score = sum(scores.values())

    # í‚¤ì›Œë“œê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš°
    if best_score < min_hits or total_score == 0:
        return "unknown"

    confidence = best_score / total_score

    # ì¶©ë¶„íˆ ì§€ë°°ì ì¸ ê²½ìš°ë§Œ í™•ì •
    if confidence >= ratio_threshold:
        return best_animal

    return "unknown"


# =========================
# 2ï¸âƒ£ CSV â†’ Pinecone Ingest
# =========================

def ingest_csv(csv_path="/home/ys0660/happycat/data/data.csv"):
    # 1ï¸âƒ£ CSV ë¡œë“œ
    df = pd.read_csv(csv_path)

    df = df.dropna(subset=["answer", "question"])
    df = df.fillna("")

    # sanity check
    for i, row in df.iterrows():
        if pd.isna(row.get("url")) or pd.isna(row.get("answer_type")):
            print("BAD ROW:", i, row)
            break

    # 2ï¸âƒ£ Pinecone client
    pc = Pinecone(
        api_key=PINECONE_API_KEY
    )

    # 3ï¸âƒ£ Embeddings
    embeddings = OpenAIEmbeddings(
        openai_api_key=OPENAI_API_KEY
    )

    # 4ï¸âƒ£ Document ìƒì„±
    docs = []

    for _, row in df.iterrows():
        question = str(row.get("question", ""))
        title = str(row.get("title", ""))
        answer = str(row.get("answer_clean", ""))
        url = str(row.get("url", ""))
        answer_type = str(row.get("answer_type", "unknown"))

        # ğŸ”¹ ë™ë¬¼ ì¢…ë¥˜ íŒë‹¨ (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
        animal = detect_animal(
            question=question,
            title=title,
        )

        # ğŸ”¥ ì¦ìƒ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        symptom_category, symptom_confidence = categorize_text(question)

        # Q + A ê²°í•© (retrieval ëŒ€ìƒ)
        page_content = f"Q: {question}\nA: {answer}"

        docs.append(
            Document(
                page_content=page_content,
                metadata={
                    # ê¸°ì¡´ í•„ë“œ
                    "question": question,
                    "title": title,
                    "url": url,
                    "answer_type": answer_type,
                    "animal": animal,

                    # ì‹ ê·œ í•„ë“œ
                    "symptom_category": symptom_category,
                    "symptom_confidence": symptom_confidence,
                }
            )
        )

    print(f"Loaded {len(docs)} documents from CSV")

    # 5ï¸âƒ£ VectorStore ì—°ê²° (ê¸°ì¡´ index ì‚¬ìš©)
    vectorstore = PineconeVectorStore.from_existing_index(
        index_name=PINECONE_INDEX,
        embedding=embeddings,
    )

    # 6ï¸âƒ£ ì—…ë¡œë“œ
    vectorstore.add_documents(docs)

    print("âœ… Pinecone ingestion completed.")


if __name__ == "__main__":
    ingest_csv()
