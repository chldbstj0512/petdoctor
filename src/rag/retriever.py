from typing import List, Dict

from langchain_pinecone import PineconeVectorStore
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from sentence_transformers import CrossEncoder

from config import *

# ingest.pyÏùò animal detector Ïû¨ÏÇ¨Ïö©
from ingest import detect_animal

# üî• Ï¶ùÏÉÅ Î∂ÑÎ•òÍ∏∞ import
from categorize import categorize_text


# =========================
# Global models (1Ìöå Î°úÎìú)
# =========================

cross_encoder = CrossEncoder(
    "cross-encoder/ms-marco-MiniLM-L-6-v2"
)

rewrite_llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0
)


# =========================
# Query rewriting (history-aware)
# =========================

def rewrite_query(query: str, history: List[Dict[str, str]] = None) -> str:
    """
    historyÍ∞Ä ÏûàÏúºÎ©¥ ÏµúÍ∑º ÎåÄÌôî Îß•ÎùΩÏùÑ Ìè¨Ìï®Ìï¥ queryÎ•º Ïû¨ÏûëÏÑ±
    """

    history_text = ""
    if history:
        recent = history[-2:]  # üîë ÏµúÍ∑º 2ÌÑ¥Îßå ÏÇ¨Ïö©
        history_text = "\n".join(
            f"ÏÇ¨Ïö©Ïûê: {h['user']}\nÎãµÎ≥Ä: {h['assistant']}"
            for h in recent
        )

    prompt = f"""
Îã§ÏùåÏùÄ Î∞òÎ†§ÎèôÎ¨º Î≥¥Ìò∏ÏûêÏùò ÏßàÎ¨∏Ïù¥Îã§.
Í≤ÄÏÉâÏùÑ ÏúÑÌï¥ Î≥¥Ìò∏ÏûêÏùò Í∂ÅÍ∏àÏ¶ùÍ≥º ÏÉÅÌô©ÏùÑ Îçî Î™ÖÌôïÌûà ÎìúÎü¨ÎÇ¥Îäî ÏßàÎ¨∏ÏúºÎ°ú Î∞îÍøîÎùº.

Ïù¥Ï†Ñ ÎåÄÌôî Îß•ÎùΩ:
{history_text if history_text else "ÏóÜÏùå"}

Í∑úÏπô:
- Ïù¥Ï†Ñ ÎåÄÌôî Îß•ÎùΩÏù¥ ÏûàÎã§Î©¥ Î∞òÎìúÏãú Î∞òÏòÅÌï† Í≤É
- Î≥¥Ìò∏ÏûêÍ∞Ä ÎäêÎÇÄ Ï¶ùÏÉÅÏùò Î≥ÄÌôî(Ï¶ùÍ∞Ä, Í∞êÏÜå, ÌèâÏÜåÏôÄ Îã§Î¶Ñ)Î•º Ìè¨Ìï®Ìï† Í≤É
- Î≥¥Ìò∏ÏûêÍ∞Ä Í∂ÅÍ∏àÌï¥ÌïòÎäî Ï†ê(Ï†ïÏÉÅÏù∏ÏßÄ, Î≥ëÏõêÏóê Í∞ÄÏïº ÌïòÎäîÏßÄ Îì±)ÏùÑ ÏßàÎ¨∏ ÌòïÌÉúÎ°ú ÌôïÏû•Ìï† Í≤É
- ÌåêÎã®, Ï°∞Ïñ∏, Í∂åÏû• ÌëúÌòÑÏùÄ ÏÇ¨Ïö©ÌïòÏßÄ Îßê Í≤É
- ÏõêÏù∏ÏùÑ Îã®Ï†ïÌïòÏßÄ Îßê Í≤É
- ÏÑúÎÑà Î¨∏Ïû•ÏúºÎ°ú ÏûëÏÑ±Ìï† Í≤É
- Ï†ÑÏ≤¥Î•º ÏßàÎ¨∏ ÌòïÌÉúÎ°ú Ïú†ÏßÄÌï† Í≤É

ÏõêÎ¨∏ ÏßàÎ¨∏: {query}
Î≥ÄÌôò:
"""
    return rewrite_llm.invoke(prompt).content.strip()


# =========================
# Retrieval (Î©ÄÌã∞ÌÑ¥ ÎåÄÏùë)
# =========================

def retrieve_docs(
    query: str,
    history: List[Dict[str, str]] = None,
    k: int = 3,
    fetch_k: int = 50,
):
    """
    query + history
    ‚Üí animal ÌåêÎã® (query only)
    ‚Üí symptom category ÌåêÎã® (query only)
    ‚Üí history-aware query rewriting
    ‚Üí Pinecone retrieval (filter)
    ‚Üí cross-encoder rerank
    """

    # ===============================
    # 0Ô∏è‚É£ animal ÌåêÎã® (ÌòÑÏû¨ ÏßàÎ¨∏ Í∏∞Ï§Ä)
    # ===============================
    animal = detect_animal(question=query)
    print(f"[DEBUG] detected animal: {animal}")

    # ===============================
    # 0Ô∏è‚É£-2 symptom category ÌåêÎã®
    # ===============================
    symptom_category, symptom_conf = categorize_text(query)
    print(f"[DEBUG] symptom_category={symptom_category}, conf={symptom_conf:.3f}")

    embeddings = OpenAIEmbeddings(
        openai_api_key=OPENAI_API_KEY
    )

    vectorstore = PineconeVectorStore.from_existing_index(
        index_name=PINECONE_INDEX,
        embedding=embeddings,
    )

    # ===============================
    # 1Ô∏è‚É£ Query rewriting (üî• history Î∞òÏòÅ)
    # ===============================
    rewritten_query = rewrite_query(query, history)

    print("\n=== QUERY REWRITE DEBUG ===")
    print("ORIGINAL :", query)
    print("HISTORY  :", history[-2:] if history else "None")
    print("REWRITTEN:", rewritten_query)
    print("==========================\n")

    # ===============================
    # 2Ô∏è‚É£ Pinecone filter Íµ¨ÏÑ±
    # ===============================
    pinecone_filter = {}

    # animal filter
    if animal in ("cat", "dog"):
        pinecone_filter["animal"] = {"$in": [animal, "unknown"]}

    # symptom filter (confidence Í∏∞Ï§Ä)
    if symptom_conf >= 0.5 and symptom_category != "ÎØ∏Î∂ÑÎ•ò":
        pinecone_filter["symptom_category"] = symptom_category

    print(f"[DEBUG] pinecone_filter = {pinecone_filter}")

    # ===============================
    # 3Ô∏è‚É£ Pinecone recall
    # ===============================
    docs = vectorstore.similarity_search(
        rewritten_query,
        k=fetch_k,
        filter=pinecone_filter if pinecone_filter else None
    )

    if not docs:
        print("[WARN] Pinecone returned 0 documents.")
        return []

    # ===============================
    # 4Ô∏è‚É£ Cross-Encoder reranking
    # ===============================
    pairs = [
        (rewritten_query, d.page_content)
        for d in docs
    ]

    scores = cross_encoder.predict(pairs)

    reranked = []
    for doc, score in zip(docs, scores):
        penalty = 0.0

        if doc.metadata.get("animal") == "unknown":
            penalty += 0.3

        if symptom_conf >= 0.5:
            if doc.metadata.get("symptom_category") != symptom_category:
                penalty += 0.5

        reranked.append((doc, score - penalty))

    reranked = sorted(
        reranked,
        key=lambda x: x[1],
        reverse=True
    )

    # ===============================
    # 5Ô∏è‚É£ Debug Ï∂úÎ†•
    # ===============================
    print("\n================ RERANK DEBUG ====================")
    for i, (doc, score) in enumerate(reranked[:k]):
        print(f"[RERANK {i}] score={score:.4f}")
        print("ANIMAL:", doc.metadata.get("animal"))
        print("SYMPTOM:", doc.metadata.get("symptom_category"))
        print("URL:", doc.metadata.get("url"))
        print("QUESTION:", doc.metadata.get("question"))
        print("CONTENT (HEAD):")
        print(doc.page_content[:300])
        print("------------------------------------------------")
    print("=================================================\n")

    return [doc for doc, _ in reranked[:k]]
